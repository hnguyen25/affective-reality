# Affective Reality

## About
Affective reality is a [Stanford BCI](https://stanfordbci.com) project which seeks to use biometric data to recognize one's emotional and focused state, and then use this to inform a virtual reality environment--whether that be a meditation app whose environment and soundscape changes depending on mood and relaxation, or an education app that monitors focus to increase learning outcomes. The end goal is to create a closed loop, bi-directional system wherein one's mental states influences the VR environment, and conversely, the VR environment influences one's mental state.

## Documentation
To read more about this codebase, visit this link:

## How to run
The project consists of two parts:
(A) Machine learning models which classifies EEG data into various emotional/affective metrics
(B) A VR application made with Unity, which is used to collect experimental EEG data for emotional classification
(C) A VR application made with Unity, which does real-time, emotion classification based on (A) and (B)

In order to run part (A) of the project:

In order to run part (B) of the project:

In order to run part (C) of the project:

## Licensing
This project is licensed under 
